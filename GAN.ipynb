{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO82z8ErbAtBPHbrHFtplm+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lee-seong-wook/ML-DL-study/blob/main/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5sezDsVRTfh"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, LeakyReLU, UpSampling2D, Conv2D\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 생성자 모델 만둘가\n",
        "generator = Sequential()\n",
        "generator.add(Dense(128 * 7 * 7, input_dim=100, activation='relu'))\n",
        "generator.add(Reshape((7,7,128)))\n",
        "generator.add(UpSampling2D())\n",
        "generator.add(Conv2D(128, kernel_size=3, padding='same'))\n",
        "generator.add(BatchNormalization())\n",
        "generator.add(Activation('relu'))\n",
        "generator.add(UpSampling2D())\n",
        "generator.add(Conv2D(64, kernel_size=3, padding='same'))\n",
        "generator.add(BatchNormalization())\n",
        "generator.add(Activation('relu'))\n",
        "generator.add(Conv2D(1, kernel_size=3, padding='same', activation='tanh'))\n",
        "\n",
        "# 판별자 모델 만들기\n",
        "discriminator = Sequential()\n",
        "discriminator.add(Conv2D(32, kernel_size=3, strides=2, input_shape=(28,28,1), padding=\"same\", activation=LeakyReLU(0.2)))\n",
        "discriminator.add(Dropout(0.25))\n",
        "discriminator.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
        "discriminator.add(BatchNormalization())\n",
        "discriminator.add(LeakyReLU(0.2))\n",
        "discriminator.add(Dropout(0.25))\n",
        "discriminator.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
        "discriminator.add(BatchNormalization())\n",
        "discriminator.add(LeakyReLU(0.2))\n",
        "discriminator.add(Dropout(0.25))\n",
        "discriminator.add(Conv2D(256, kernel_size=3, strides=2, padding=\"same\"))\n",
        "discriminator.add(BatchNormalization())\n",
        "discriminator.add(LeakyReLU(0.2))\n",
        "discriminator.add(Dropout(0.25))\n",
        "discriminator.add(Flatten())\n",
        "discriminator.add(Dense(1, activation='sigmoid'))\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "discriminator.trainable = False\n",
        "\n",
        "# 생성자와 판별자 모델을 연결시키는 gan 모델 만들기\n",
        "ginput = Input(shape=(100,))\n",
        "print(ginput)\n",
        "dis_output = discriminator(generator(ginput))\n",
        "gan = Model(ginput, dis_output)\n",
        "gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "gan.summary()\n",
        "\n",
        "# 신경망을 실행시키는 함수 만들기\n",
        "def gan_train(epoch, batch_size, saving_interval):\n",
        "\n",
        "# MNIST 데이터 불러오기\n",
        "\n",
        "  (X_train, _), (_, _) = mnist.load_data()  # 앞서 불러온 MNIST를 다시 이용, 테스트 과정은 필요없고 이미지만 사용할 것이기 때문에 X_train만 호출\n",
        "  X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
        "  X_train = (X_train - 127.5) / 127.5  # 픽셀 값은 0~255사이의 값. 이전에 255로 나눠줄 때는 이를 0~1사이의 값으로 바꿨던 것인데, 여기서는 127.5를 빼준 뒤 127.5로 나눠서 -1~1사이의 값으로 바뀜\n",
        "\n",
        "  true = np.ones((batch_size, 1))\n",
        "  fake = np.zeros((batch_size, 1))\n",
        "\n",
        "  for i in range(epoch):\n",
        "          # 실제 데이터를 판별자에 입력\n",
        "          idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "          imgs = X_train[idx]\n",
        "          d_loss_real = discriminator.train_on_batch(imgs, true)\n",
        "\n",
        "          #가상 이미지를 판별자에 입력\n",
        "          noise = np.random.normal(0, 1, (batch_size, 100))\n",
        "          gen_imgs = generator.predict(noise)\n",
        "          d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
        "\n",
        "          # 판별자와 생성자의 오차 계산\n",
        "          d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "          g_loss = gan.train_on_batch(noise, true)\n",
        "\n",
        "          print('epoch:%d' % i, ' d_loss:%.4f' % d_loss, ' g_loss:%.4f' % g_loss)\n",
        "\n",
        "        # 중간 과정을 이미지로 저장하는 부분. 정해진 인터벌(saving_interval)만큼 학습되면 그때 만든 이미지를 gan_images 폴더에 저장하라는 뜻. 이 코드는 본 장의 주된 목표와는 관계가 없어서 소스 코드만 소개한다\n",
        "\n",
        "          if i % saving_interval == 0:\n",
        "              # r, c = 5, 5\n",
        "              noise = np.random.normal(0, 1, (25, 100))\n",
        "              gen_imgs = generator.predict(noise)\n",
        "\n",
        "              # Rescale images 0 - 1\n",
        "              gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "              fig, axs = plt.subplots(5, 5)\n",
        "              count = 0\n",
        "              for j in range(5):\n",
        "                  for k in range(5):\n",
        "                      axs[j, k].imshow(gen_imgs[count, :, :, 0], cmap='gray')\n",
        "                      axs[j, k].axis('off')\n",
        "                      count += 1\n",
        "              fig.savefig(\"/content/sample_data/%d.png\" % i)\n",
        "\n",
        "gan_train(4001, 32, 200)  # 4000번 반복되고(+1을 하는 것에 주의), 배치 크기는 32,  200번마다 결과가 저장됨"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xrf-wPX7UxIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M5p23-xnUytA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# MNIST데이터 셋을 호출\n",
        "(X_train, _), (X_test, _) = mnist.load_data()\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "\n",
        "# 생성자 모델 만들기\n",
        "autoencoder = Sequential()\n",
        "\n",
        "# 인코딩 부분\n",
        "autoencoder.add(Conv2D(16, kernel_size=3, padding='same', input_shape=(28,28,1), activation='relu'))\n",
        "autoencoder.add(MaxPooling2D(pool_size=2, padding='same'))\n",
        "autoencoder.add(Conv2D(8, kernel_size=3, activation='relu', padding='same'))\n",
        "autoencoder.add(MaxPooling2D(pool_size=2, padding='same'))\n",
        "autoencoder.add(Conv2D(8, kernel_size=3, strides=2, padding='same', activation='relu'))\n",
        "\n",
        "# 디코딩 부분\n",
        "autoencoder.add(Conv2D(8, kernel_size=3, padding='same', activation='relu'))\n",
        "autoencoder.add(UpSampling2D())\n",
        "autoencoder.add(Conv2D(8, kernel_size=3, padding='same', activation='relu'))\n",
        "autoencoder.add(UpSampling2D())\n",
        "autoencoder.add(Conv2D(16, kernel_size=3, activation='relu'))\n",
        "autoencoder.add(UpSampling2D())\n",
        "autoencoder.add(Conv2D(1, kernel_size=3, padding='same', activation='sigmoid'))\n",
        "\n",
        "# 전체 구조 확인\n",
        "autoencoder.summary()\n",
        "\n",
        "# 컴파일 및 학습을 하는 부분\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "autoencoder.fit(X_train, X_train, epochs=50, batch_size=128, validation_data=(X_test, X_test))\n",
        "\n",
        "# 학습된 결과를 출력하는 부분\n",
        "random_test = np.random.randint(X_test.shape[0], size=5)  # 테스트할 이미지를 랜덤으로 호출.\n",
        "ae_imgs = autoencoder.predict(X_test)  # 앞서 만든 오토인코더 모델에 집어넣이기\n",
        "\n",
        "plt.figure(figsize=(7, 2))  # 출력될 이미지의 크기를 정하기\n",
        "\n",
        "for i, image_idx in enumerate(random_test):    # 랜덤으로 뽑은 이미지를 차례로 나열\n",
        "   ax = plt.subplot(2, 7, i + 1)\n",
        "   plt.imshow(X_test[image_idx].reshape(28, 28))  # 테스트할 이미지를 먼저 그대로 보여줌\n",
        "   ax.axis('off')\n",
        "   ax = plt.subplot(2, 7, 7 + i +1)\n",
        "   plt.imshow(ae_imgs[image_idx].reshape(28, 28))  # 오토인코딩 결과를 다음 열에 입력\n",
        "   ax.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dfyQgukFTvIM",
        "outputId": "7999058e-19fa-4b7b-ea13-0df39f88033e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_28 (Conv2D)          (None, 28, 28, 16)        160       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 14, 14, 16)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 14, 14, 8)         1160      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 8)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 4, 4, 8)           584       \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 4, 4, 8)           584       \n",
            "                                                                 \n",
            " up_sampling2d_8 (UpSamplin  (None, 8, 8, 8)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 8, 8, 8)           584       \n",
            "                                                                 \n",
            " up_sampling2d_9 (UpSamplin  (None, 16, 16, 8)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 14, 14, 16)        1168      \n",
            "                                                                 \n",
            " up_sampling2d_10 (UpSampli  (None, 28, 28, 16)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (None, 28, 28, 1)         145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4385 (17.13 KB)\n",
            "Trainable params: 4385 (17.13 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "469/469 [==============================] - 64s 131ms/step - loss: 0.1987 - val_loss: 0.1349\n",
            "Epoch 2/50\n",
            "469/469 [==============================] - 59s 126ms/step - loss: 0.1248 - val_loss: 0.1152\n",
            "Epoch 3/50\n",
            "469/469 [==============================] - 58s 124ms/step - loss: 0.1120 - val_loss: 0.1075\n",
            "Epoch 4/50\n",
            "469/469 [==============================] - 59s 125ms/step - loss: 0.1062 - val_loss: 0.1028\n",
            "Epoch 5/50\n",
            "469/469 [==============================] - 58s 124ms/step - loss: 0.1025 - val_loss: 0.1000\n",
            "Epoch 6/50\n",
            "469/469 [==============================] - 59s 125ms/step - loss: 0.1000 - val_loss: 0.0977\n",
            "Epoch 7/50\n",
            "469/469 [==============================] - 58s 124ms/step - loss: 0.0983 - val_loss: 0.0965\n",
            "Epoch 8/50\n",
            "469/469 [==============================] - 61s 129ms/step - loss: 0.0968 - val_loss: 0.0949\n",
            "Epoch 9/50\n",
            "469/469 [==============================] - 58s 124ms/step - loss: 0.0957 - val_loss: 0.0940\n",
            "Epoch 10/50\n",
            "469/469 [==============================] - 58s 124ms/step - loss: 0.0947 - val_loss: 0.0930\n",
            "Epoch 11/50\n",
            "469/469 [==============================] - 59s 125ms/step - loss: 0.0937 - val_loss: 0.0921\n",
            "Epoch 12/50\n",
            "469/469 [==============================] - 58s 125ms/step - loss: 0.0929 - val_loss: 0.0912\n",
            "Epoch 13/50\n",
            "469/469 [==============================] - 59s 126ms/step - loss: 0.0922 - val_loss: 0.0907\n",
            "Epoch 14/50\n",
            "469/469 [==============================] - 59s 126ms/step - loss: 0.0915 - val_loss: 0.0900\n",
            "Epoch 15/50\n",
            "469/469 [==============================] - 59s 125ms/step - loss: 0.0910 - val_loss: 0.0904\n",
            "Epoch 16/50\n",
            "469/469 [==============================] - 58s 124ms/step - loss: 0.0905 - val_loss: 0.0890\n",
            "Epoch 17/50\n",
            "469/469 [==============================] - 58s 124ms/step - loss: 0.0900 - val_loss: 0.0887\n",
            "Epoch 18/50\n",
            "469/469 [==============================] - 58s 123ms/step - loss: 0.0895 - val_loss: 0.0881\n",
            "Epoch 19/50\n",
            "469/469 [==============================] - 58s 124ms/step - loss: 0.0891 - val_loss: 0.0877\n",
            "Epoch 20/50\n",
            "469/469 [==============================] - 58s 124ms/step - loss: 0.0888 - val_loss: 0.0873\n",
            "Epoch 21/50\n",
            "469/469 [==============================] - 58s 123ms/step - loss: 0.0884 - val_loss: 0.0872\n",
            "Epoch 22/50\n",
            "469/469 [==============================] - 58s 123ms/step - loss: 0.0881 - val_loss: 0.0867\n",
            "Epoch 23/50\n",
            "469/469 [==============================] - 58s 124ms/step - loss: 0.0877 - val_loss: 0.0867\n",
            "Epoch 24/50\n",
            "469/469 [==============================] - 58s 123ms/step - loss: 0.0874 - val_loss: 0.0860\n",
            "Epoch 25/50\n",
            "469/469 [==============================] - 58s 124ms/step - loss: 0.0870 - val_loss: 0.0860\n",
            "Epoch 26/50\n",
            "469/469 [==============================] - 58s 124ms/step - loss: 0.0868 - val_loss: 0.0855\n",
            "Epoch 27/50\n",
            "469/469 [==============================] - 58s 123ms/step - loss: 0.0865 - val_loss: 0.0853\n",
            "Epoch 28/50\n",
            "469/469 [==============================] - 58s 124ms/step - loss: 0.0862 - val_loss: 0.0849\n",
            "Epoch 29/50\n",
            "469/469 [==============================] - 58s 124ms/step - loss: 0.0859 - val_loss: 0.0848\n",
            "Epoch 30/50\n",
            "469/469 [==============================] - 58s 124ms/step - loss: 0.0857 - val_loss: 0.0847\n",
            "Epoch 31/50\n",
            "469/469 [==============================] - 58s 124ms/step - loss: 0.0854 - val_loss: 0.0843\n",
            "Epoch 32/50\n",
            "469/469 [==============================] - 58s 123ms/step - loss: 0.0852 - val_loss: 0.0844\n",
            "Epoch 33/50\n",
            "469/469 [==============================] - 58s 123ms/step - loss: 0.0850 - val_loss: 0.0839\n",
            "Epoch 34/50\n",
            "469/469 [==============================] - 58s 125ms/step - loss: 0.0849 - val_loss: 0.0839\n",
            "Epoch 35/50\n",
            "469/469 [==============================] - 58s 123ms/step - loss: 0.0847 - val_loss: 0.0837\n",
            "Epoch 36/50\n",
            "469/469 [==============================] - 58s 124ms/step - loss: 0.0846 - val_loss: 0.0835\n",
            "Epoch 37/50\n",
            "469/469 [==============================] - 58s 123ms/step - loss: 0.0844 - val_loss: 0.0833\n",
            "Epoch 38/50\n",
            "469/469 [==============================] - 58s 123ms/step - loss: 0.0843 - val_loss: 0.0833\n",
            "Epoch 39/50\n",
            "469/469 [==============================] - 58s 123ms/step - loss: 0.0842 - val_loss: 0.0832\n",
            "Epoch 40/50\n",
            "469/469 [==============================] - 58s 123ms/step - loss: 0.0841 - val_loss: 0.0832\n",
            "Epoch 41/50\n",
            "469/469 [==============================] - 58s 123ms/step - loss: 0.0840 - val_loss: 0.0829\n",
            "Epoch 42/50\n",
            "469/469 [==============================] - 58s 123ms/step - loss: 0.0838 - val_loss: 0.0828\n",
            "Epoch 43/50\n",
            "469/469 [==============================] - 58s 123ms/step - loss: 0.0838 - val_loss: 0.0830\n",
            "Epoch 44/50\n",
            "469/469 [==============================] - 58s 123ms/step - loss: 0.0836 - val_loss: 0.0825\n",
            "Epoch 45/50\n",
            "469/469 [==============================] - 58s 123ms/step - loss: 0.0835 - val_loss: 0.0826\n",
            "Epoch 46/50\n",
            "469/469 [==============================] - 58s 124ms/step - loss: 0.0835 - val_loss: 0.0824\n",
            "Epoch 47/50\n",
            "469/469 [==============================] - 58s 123ms/step - loss: 0.0834 - val_loss: 0.0824\n",
            "Epoch 48/50\n",
            "469/469 [==============================] - 58s 123ms/step - loss: 0.0833 - val_loss: 0.0823\n",
            "Epoch 49/50\n",
            "469/469 [==============================] - 59s 126ms/step - loss: 0.0832 - val_loss: 0.0821\n",
            "Epoch 50/50\n",
            "469/469 [==============================] - 58s 123ms/step - loss: 0.0831 - val_loss: 0.0821\n",
            "313/313 [==============================] - 3s 9ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x200 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization, Reshape, Flatten, Input, Conv2D, UpSampling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# WGAN-GP에서 사용하는 Gradient Penalty 함수\n",
        "def gradient_penalty_loss(y_true, y_pred, averaged_samples):\n",
        "    gradients = K.gradients(y_pred, averaged_samples)[0]\n",
        "    gradients_sqr = K.square(gradients)\n",
        "    gradient_penalty = K.sum(gradients_sqr, axis=np.arange(1, len(gradients_sqr.shape)))\n",
        "    return K.mean(gradient_penalty)\n",
        "\n",
        "def build_generator(latent_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(256, input_dim=latent_dim))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(1024))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(28 * 28 * 1, activation='tanh'))\n",
        "    model.add(Reshape((28, 28, 1)))\n",
        "    return model\n",
        "\n",
        "def build_discriminator(img_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=img_shape))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(128))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(1))\n",
        "    return model\n",
        "\n",
        "def build_gan(generator, discriminator):\n",
        "    z = Input(shape=(latent_dim,))\n",
        "    img = generator(z)\n",
        "    validity = discriminator(img)\n",
        "    return Model(z, validity)\n",
        "\n",
        "def train_gan(generator, discriminator, gan, epochs, batch_size, latent_dim, sample_interval=100):\n",
        "    (X_train, _), (_, _) = fashion_mnist.load_data()\n",
        "    X_train = X_train / 127.5 - 1.0\n",
        "    X_train = np.expand_dims(X_train, axis=3)\n",
        "\n",
        "    # 판별자 모델 컴파일\n",
        "    discriminator.compile(loss=wasserstein_loss, optimizer=Adam(learning_rate=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
        "\n",
        "    # 생성자와 GAN 모델 컴파일\n",
        "    gan.compile(loss=wasserstein_loss, optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        d_loss_total = 0.0\n",
        "        g_loss_total = 0.0\n",
        "\n",
        "        for _ in range(X_train.shape[0] // batch_size):\n",
        "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "            imgs = X_train[idx]\n",
        "\n",
        "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "            gen_imgs = generator.predict(noise)\n",
        "\n",
        "            d_loss_real = discriminator.train_on_batch(imgs, -np.ones((batch_size, 1)))\n",
        "            d_loss_fake = discriminator.train_on_batch(gen_imgs, np.ones((batch_size, 1)))\n",
        "            d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
        "\n",
        "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "            valid_y = -np.ones((batch_size, 1))\n",
        "            g_loss = gan.train_on_batch(noise, valid_y)\n",
        "\n",
        "            d_loss_total += d_loss\n",
        "            g_loss_total += g_loss\n",
        "\n",
        "        # 각 에폭의 평균 손실 출력\n",
        "        d_loss_avg = d_loss_total / (X_train.shape[0] // batch_size)\n",
        "        g_loss_avg = g_loss_total / (X_train.shape[0] // batch_size)\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, D Loss: {d_loss_avg[0]}, G Loss: {g_loss_avg[0]}\")\n",
        "\n",
        "        if epoch % sample_interval == 0:\n",
        "            generate_and_save_images(generator, epoch, latent_dim)\n",
        "\n",
        "\n",
        "def generate_and_save_images(generator, epoch, latent_dim, examples=100, dim=(10, 10), figsize=(10, 10)):\n",
        "    noise = np.random.normal(0, 1, size=[examples, latent_dim])\n",
        "    generated_images = generator.predict(noise)\n",
        "    generated_images = generated_images.reshape(examples, 28, 28)\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    for i in range(generated_images.shape[0]):\n",
        "        plt.subplot(dim[0], dim[1], i + 1)\n",
        "        plt.imshow(generated_images[i], interpolation='nearest', cmap='gray_r')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'generated_images_epoch_{epoch}.png')\n",
        "\n",
        "# Hyperparameters\n",
        "latent_dim = 100\n",
        "img_shape = (28, 28, 1)\n",
        "epochs = 20000\n",
        "batch_size = 128\n",
        "\n",
        "# WGAN-GP에서 사용하는 Wasserstein Loss 함수\n",
        "def wasserstein_loss(y_true, y_pred):\n",
        "    return K.mean(y_true * y_pred)\n",
        "\n",
        "# 모델 생성 및 학습\n",
        "generator = build_generator(latent_dim)\n",
        "discriminator = build_discriminator(img_shape)\n",
        "gan = build_gan(generator, discriminator)\n",
        "\n",
        "# 훈련\n",
        "train_gan(generator, discriminator, gan, epochs, batch_size, latent_dim)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0KKPdR2K1RDm",
        "outputId": "63ce7e94-cd11-4ac0-a540-796dedcb5c49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 12ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 10ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 10ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 10ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 10ms/step\n",
            "4/4 [==============================] - 0s 11ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 10ms/step\n",
            "4/4 [==============================] - 0s 11ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 10ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 10ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 11ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-447dfb592828>\u001b[0m in \u001b[0;36m<cell line: 123>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;31m# 훈련\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m \u001b[0mtrain_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-55-447dfb592828>\u001b[0m in \u001b[0;36mtrain_gan\u001b[0;34m(generator, discriminator, gan, epochs, batch_size, latent_dim, sample_interval)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0md_loss_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_loss_total\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mg_loss_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_loss_total\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch + 1}/{epochs}, D Loss: {d_loss_avg[0]}, G Loss: {g_loss_avg[0]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msample_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow-addons\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NA8VSAtDGl7k",
        "outputId": "5c46ef1e-4ce1-4cfb-b6d7-c7b61052b3fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.3/612.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.22.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 샘플 텍스트 데이터\n",
        "text_data = \"\"\"\n",
        "Hello, how are you doing today?\n",
        "I hope everything is going well.\n",
        "This is a simple text generation example.\n",
        "You can replace this with your own text data.\n",
        "\"\"\"\n",
        "\n",
        "# 텍스트 데이터 전처리\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text_data])\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# 문장을 시퀀스로 변환\n",
        "input_sequences = []\n",
        "for line in text_data.split('\\n'):\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# 패딩 및 입력/출력 데이터 생성\n",
        "max_sequence_length = max([len(x) for x in input_sequences])\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n",
        "X, y = input_sequences[:,:-1], input_sequences[:,-1]\n",
        "y = to_categorical(y, num_classes=total_words)\n",
        "\n",
        "# LSTM 모델 생성\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_length-1))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01), metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=100, verbose=2)\n",
        "\n",
        "## 텍스트 생성 함수\n",
        "def generate_text(seed_text, next_words, model, max_sequence_length):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')\n",
        "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
        "\n",
        "        # 가장 확률이 높은 단어의 인덱스 찾기\n",
        "        predicted_index = np.argmax(predicted_probs)\n",
        "\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted_index:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n",
        "\n",
        "# 새로운 텍스트 생성\n",
        "generated_text = generate_text(\"Hello\", 10, model, max_sequence_length)\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBy6POhfYY4g",
        "outputId": "b9705dfc-718b-43b3-d53d-0f11389592d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 - 3s - loss: 3.2229 - accuracy: 0.0000e+00 - 3s/epoch - 3s/step\n",
            "Epoch 2/100\n",
            "1/1 - 0s - loss: 3.2157 - accuracy: 0.0000e+00 - 15ms/epoch - 15ms/step\n",
            "Epoch 3/100\n",
            "1/1 - 0s - loss: 3.2087 - accuracy: 0.0417 - 15ms/epoch - 15ms/step\n",
            "Epoch 4/100\n",
            "1/1 - 0s - loss: 3.2016 - accuracy: 0.0833 - 15ms/epoch - 15ms/step\n",
            "Epoch 5/100\n",
            "1/1 - 0s - loss: 3.1945 - accuracy: 0.0833 - 16ms/epoch - 16ms/step\n",
            "Epoch 6/100\n",
            "1/1 - 0s - loss: 3.1871 - accuracy: 0.0833 - 16ms/epoch - 16ms/step\n",
            "Epoch 7/100\n",
            "1/1 - 0s - loss: 3.1794 - accuracy: 0.0833 - 16ms/epoch - 16ms/step\n",
            "Epoch 8/100\n",
            "1/1 - 0s - loss: 3.1712 - accuracy: 0.0833 - 21ms/epoch - 21ms/step\n",
            "Epoch 9/100\n",
            "1/1 - 0s - loss: 3.1624 - accuracy: 0.0833 - 21ms/epoch - 21ms/step\n",
            "Epoch 10/100\n",
            "1/1 - 0s - loss: 3.1529 - accuracy: 0.0833 - 14ms/epoch - 14ms/step\n",
            "Epoch 11/100\n",
            "1/1 - 0s - loss: 3.1424 - accuracy: 0.0833 - 16ms/epoch - 16ms/step\n",
            "Epoch 12/100\n",
            "1/1 - 0s - loss: 3.1309 - accuracy: 0.0833 - 15ms/epoch - 15ms/step\n",
            "Epoch 13/100\n",
            "1/1 - 0s - loss: 3.1180 - accuracy: 0.0833 - 15ms/epoch - 15ms/step\n",
            "Epoch 14/100\n",
            "1/1 - 0s - loss: 3.1036 - accuracy: 0.0833 - 14ms/epoch - 14ms/step\n",
            "Epoch 15/100\n",
            "1/1 - 0s - loss: 3.0874 - accuracy: 0.0833 - 15ms/epoch - 15ms/step\n",
            "Epoch 16/100\n",
            "1/1 - 0s - loss: 3.0694 - accuracy: 0.0833 - 15ms/epoch - 15ms/step\n",
            "Epoch 17/100\n",
            "1/1 - 0s - loss: 3.0496 - accuracy: 0.0833 - 16ms/epoch - 16ms/step\n",
            "Epoch 18/100\n",
            "1/1 - 0s - loss: 3.0284 - accuracy: 0.0833 - 17ms/epoch - 17ms/step\n",
            "Epoch 19/100\n",
            "1/1 - 0s - loss: 3.0068 - accuracy: 0.0833 - 19ms/epoch - 19ms/step\n",
            "Epoch 20/100\n",
            "1/1 - 0s - loss: 2.9869 - accuracy: 0.0833 - 17ms/epoch - 17ms/step\n",
            "Epoch 21/100\n",
            "1/1 - 0s - loss: 2.9704 - accuracy: 0.0833 - 15ms/epoch - 15ms/step\n",
            "Epoch 22/100\n",
            "1/1 - 0s - loss: 2.9553 - accuracy: 0.0833 - 14ms/epoch - 14ms/step\n",
            "Epoch 23/100\n",
            "1/1 - 0s - loss: 2.9368 - accuracy: 0.0833 - 21ms/epoch - 21ms/step\n",
            "Epoch 24/100\n",
            "1/1 - 0s - loss: 2.9123 - accuracy: 0.1250 - 17ms/epoch - 17ms/step\n",
            "Epoch 25/100\n",
            "1/1 - 0s - loss: 2.8836 - accuracy: 0.1250 - 20ms/epoch - 20ms/step\n",
            "Epoch 26/100\n",
            "1/1 - 0s - loss: 2.8537 - accuracy: 0.1667 - 19ms/epoch - 19ms/step\n",
            "Epoch 27/100\n",
            "1/1 - 0s - loss: 2.8245 - accuracy: 0.1667 - 17ms/epoch - 17ms/step\n",
            "Epoch 28/100\n",
            "1/1 - 0s - loss: 2.7957 - accuracy: 0.1667 - 15ms/epoch - 15ms/step\n",
            "Epoch 29/100\n",
            "1/1 - 0s - loss: 2.7657 - accuracy: 0.2083 - 15ms/epoch - 15ms/step\n",
            "Epoch 30/100\n",
            "1/1 - 0s - loss: 2.7326 - accuracy: 0.2083 - 15ms/epoch - 15ms/step\n",
            "Epoch 31/100\n",
            "1/1 - 0s - loss: 2.6952 - accuracy: 0.2083 - 15ms/epoch - 15ms/step\n",
            "Epoch 32/100\n",
            "1/1 - 0s - loss: 2.6531 - accuracy: 0.2083 - 15ms/epoch - 15ms/step\n",
            "Epoch 33/100\n",
            "1/1 - 0s - loss: 2.6075 - accuracy: 0.2083 - 15ms/epoch - 15ms/step\n",
            "Epoch 34/100\n",
            "1/1 - 0s - loss: 2.5600 - accuracy: 0.2083 - 16ms/epoch - 16ms/step\n",
            "Epoch 35/100\n",
            "1/1 - 0s - loss: 2.5105 - accuracy: 0.2083 - 25ms/epoch - 25ms/step\n",
            "Epoch 36/100\n",
            "1/1 - 0s - loss: 2.4565 - accuracy: 0.2083 - 14ms/epoch - 14ms/step\n",
            "Epoch 37/100\n",
            "1/1 - 0s - loss: 2.3965 - accuracy: 0.2083 - 19ms/epoch - 19ms/step\n",
            "Epoch 38/100\n",
            "1/1 - 0s - loss: 2.3342 - accuracy: 0.2917 - 15ms/epoch - 15ms/step\n",
            "Epoch 39/100\n",
            "1/1 - 0s - loss: 2.2724 - accuracy: 0.3750 - 16ms/epoch - 16ms/step\n",
            "Epoch 40/100\n",
            "1/1 - 0s - loss: 2.2057 - accuracy: 0.4167 - 15ms/epoch - 15ms/step\n",
            "Epoch 41/100\n",
            "1/1 - 0s - loss: 2.1326 - accuracy: 0.4167 - 15ms/epoch - 15ms/step\n",
            "Epoch 42/100\n",
            "1/1 - 0s - loss: 2.0624 - accuracy: 0.4167 - 15ms/epoch - 15ms/step\n",
            "Epoch 43/100\n",
            "1/1 - 0s - loss: 1.9905 - accuracy: 0.4167 - 14ms/epoch - 14ms/step\n",
            "Epoch 44/100\n",
            "1/1 - 0s - loss: 1.9165 - accuracy: 0.4583 - 18ms/epoch - 18ms/step\n",
            "Epoch 45/100\n",
            "1/1 - 0s - loss: 1.8477 - accuracy: 0.5000 - 15ms/epoch - 15ms/step\n",
            "Epoch 46/100\n",
            "1/1 - 0s - loss: 1.7736 - accuracy: 0.5000 - 17ms/epoch - 17ms/step\n",
            "Epoch 47/100\n",
            "1/1 - 0s - loss: 1.7066 - accuracy: 0.5000 - 14ms/epoch - 14ms/step\n",
            "Epoch 48/100\n",
            "1/1 - 0s - loss: 1.6338 - accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
            "Epoch 49/100\n",
            "1/1 - 0s - loss: 1.5684 - accuracy: 0.5833 - 15ms/epoch - 15ms/step\n",
            "Epoch 50/100\n",
            "1/1 - 0s - loss: 1.5042 - accuracy: 0.5833 - 17ms/epoch - 17ms/step\n",
            "Epoch 51/100\n",
            "1/1 - 0s - loss: 1.4416 - accuracy: 0.6250 - 15ms/epoch - 15ms/step\n",
            "Epoch 52/100\n",
            "1/1 - 0s - loss: 1.3867 - accuracy: 0.7500 - 17ms/epoch - 17ms/step\n",
            "Epoch 53/100\n",
            "1/1 - 0s - loss: 1.3304 - accuracy: 0.6667 - 15ms/epoch - 15ms/step\n",
            "Epoch 54/100\n",
            "1/1 - 0s - loss: 1.2776 - accuracy: 0.7500 - 15ms/epoch - 15ms/step\n",
            "Epoch 55/100\n",
            "1/1 - 0s - loss: 1.2322 - accuracy: 0.8333 - 14ms/epoch - 14ms/step\n",
            "Epoch 56/100\n",
            "1/1 - 0s - loss: 1.1851 - accuracy: 0.7917 - 15ms/epoch - 15ms/step\n",
            "Epoch 57/100\n",
            "1/1 - 0s - loss: 1.1403 - accuracy: 0.7917 - 15ms/epoch - 15ms/step\n",
            "Epoch 58/100\n",
            "1/1 - 0s - loss: 1.0991 - accuracy: 0.8333 - 16ms/epoch - 16ms/step\n",
            "Epoch 59/100\n",
            "1/1 - 0s - loss: 1.0590 - accuracy: 0.8333 - 15ms/epoch - 15ms/step\n",
            "Epoch 60/100\n",
            "1/1 - 0s - loss: 1.0254 - accuracy: 0.8750 - 20ms/epoch - 20ms/step\n",
            "Epoch 61/100\n",
            "1/1 - 0s - loss: 0.9932 - accuracy: 0.8750 - 17ms/epoch - 17ms/step\n",
            "Epoch 62/100\n",
            "1/1 - 0s - loss: 0.9522 - accuracy: 0.8750 - 15ms/epoch - 15ms/step\n",
            "Epoch 63/100\n",
            "1/1 - 0s - loss: 0.9215 - accuracy: 0.9167 - 15ms/epoch - 15ms/step\n",
            "Epoch 64/100\n",
            "1/1 - 0s - loss: 0.8933 - accuracy: 0.8750 - 17ms/epoch - 17ms/step\n",
            "Epoch 65/100\n",
            "1/1 - 0s - loss: 0.8603 - accuracy: 0.8750 - 16ms/epoch - 16ms/step\n",
            "Epoch 66/100\n",
            "1/1 - 0s - loss: 0.8388 - accuracy: 0.9167 - 15ms/epoch - 15ms/step\n",
            "Epoch 67/100\n",
            "1/1 - 0s - loss: 0.8105 - accuracy: 0.9167 - 15ms/epoch - 15ms/step\n",
            "Epoch 68/100\n",
            "1/1 - 0s - loss: 0.7817 - accuracy: 0.9583 - 15ms/epoch - 15ms/step\n",
            "Epoch 69/100\n",
            "1/1 - 0s - loss: 0.7616 - accuracy: 0.9583 - 14ms/epoch - 14ms/step\n",
            "Epoch 70/100\n",
            "1/1 - 0s - loss: 0.7347 - accuracy: 0.9583 - 14ms/epoch - 14ms/step\n",
            "Epoch 71/100\n",
            "1/1 - 0s - loss: 0.7117 - accuracy: 0.9583 - 15ms/epoch - 15ms/step\n",
            "Epoch 72/100\n",
            "1/1 - 0s - loss: 0.6933 - accuracy: 0.9583 - 14ms/epoch - 14ms/step\n",
            "Epoch 73/100\n",
            "1/1 - 0s - loss: 0.6691 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 74/100\n",
            "1/1 - 0s - loss: 0.6503 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 75/100\n",
            "1/1 - 0s - loss: 0.6339 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 76/100\n",
            "1/1 - 0s - loss: 0.6134 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 77/100\n",
            "1/1 - 0s - loss: 0.6010 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 78/100\n",
            "1/1 - 0s - loss: 0.5844 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 79/100\n",
            "1/1 - 0s - loss: 0.5663 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 80/100\n",
            "1/1 - 0s - loss: 0.5481 - accuracy: 1.0000 - 27ms/epoch - 27ms/step\n",
            "Epoch 81/100\n",
            "1/1 - 0s - loss: 0.5308 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 82/100\n",
            "1/1 - 0s - loss: 0.5205 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
            "Epoch 83/100\n",
            "1/1 - 0s - loss: 0.5072 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 84/100\n",
            "1/1 - 0s - loss: 0.4901 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 85/100\n",
            "1/1 - 0s - loss: 0.4785 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 86/100\n",
            "1/1 - 0s - loss: 0.4671 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 87/100\n",
            "1/1 - 0s - loss: 0.4557 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
            "Epoch 88/100\n",
            "1/1 - 0s - loss: 0.4431 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 89/100\n",
            "1/1 - 0s - loss: 0.4317 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 90/100\n",
            "1/1 - 0s - loss: 0.4232 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 91/100\n",
            "1/1 - 0s - loss: 0.4114 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 92/100\n",
            "1/1 - 0s - loss: 0.4008 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 93/100\n",
            "1/1 - 0s - loss: 0.3926 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 94/100\n",
            "1/1 - 0s - loss: 0.3825 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 95/100\n",
            "1/1 - 0s - loss: 0.3732 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 96/100\n",
            "1/1 - 0s - loss: 0.3647 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 97/100\n",
            "1/1 - 0s - loss: 0.3561 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 98/100\n",
            "1/1 - 0s - loss: 0.3480 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 99/100\n",
            "1/1 - 0s - loss: 0.3395 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 100/100\n",
            "1/1 - 0s - loss: 0.3318 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Hello how are you doing today today today today data data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from nltk.corpus import reuters\n",
        "import nltk\n",
        "\n",
        "# nltk 데이터 다운로드\n",
        "nltk.download('reuters')\n",
        "\n",
        "# NLTK의 reuters 데이터셋 로드\n",
        "documents = reuters.fileids()\n",
        "train_documents = list(filter(lambda doc: doc.startswith(\"training\"), documents))\n",
        "\n",
        "# 텍스트 데이터 전처리\n",
        "text_data = \" \".join([reuters.raw(doc_id) for doc_id in train_documents[:100]])\n",
        "\n",
        "# 문장 단위로 텍스트 분할\n",
        "sentences = text_data.split('\\n')\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "input_sequences = []\n",
        "for line in sentences:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "max_sequence_length = max([len(x) for x in input_sequences])\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n",
        "X, y = input_sequences[:,:-1], input_sequences[:,-1]\n",
        "y = to_categorical(y, num_classes=total_words)\n",
        "\n",
        "# LSTM 모델 생성\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 250, input_length=max_sequence_length-1))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "# 옵티마이저 수정\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=100, verbose=2)  # 에포크 수 조절\n",
        "\n",
        "# 예제 라벨 데이터 생성\n",
        "y_true_example = to_categorical(np.random.randint(0, total_words, size=(32,)), num_classes=total_words)\n",
        "\n",
        "seed_text = \"The\"\n",
        "next_words = 30\n",
        "\n",
        "for _ in range(next_words):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')\n",
        "    predicted_probs = model.predict(token_list, verbose=0)[0]\n",
        "    predicted_index = np.argmax(predicted_probs)\n",
        "\n",
        "    # 인덱스를 단어로 변환\n",
        "    output_word = \"\"\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted_index:\n",
        "            output_word = word\n",
        "            break\n",
        "\n",
        "    seed_text += \" \" + output_word\n",
        "\n",
        "print(seed_text)\n"
      ],
      "metadata": {
        "id": "eKyL5wlNY2DR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}